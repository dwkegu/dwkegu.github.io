{"meta":{"title":"DayDream_Blog","subtitle":null,"description":"机器学习，数据挖掘，NLP技术博客","author":"Riverspeng","url":"http://dwkegu.github.io","root":"/"},"pages":[],"posts":[{"title":"字符串算法之KMP与AC算法","slug":"字符串算法之KMP与AC算法","date":"2020-02-07T14:49:20.000Z","updated":"2020-02-09T14:14:58.706Z","comments":true,"path":"2020/02/07/字符串算法之KMP与AC算法/","link":"","permalink":"http://dwkegu.github.io/2020/02/07/字符串算法之KMP与AC算法/","excerpt":"","text":"1. 介绍在字符串匹配算法中，通常分为单模式匹配和多模式匹配。常见的字符串匹配常见为单模式匹配，例如，搜索某个长串中是否存在某个子串。这种场景下$O(n)$时间效率内解决的算法是KMP算法。在多模式匹配的场景下，KMP算法并不能在线性时间内解决这个问题。需要多次遍历长串，才能实现每个模式串的匹配。AC算法就是为了解决在线性时间内进行多模式字符串匹配的问题，其时间复杂度为$O(n)$。 2. KMP算法在KMP算法之前，单模式字符串匹配需要多次扫描源字符串。为了在每次匹配失败的时候不需要重新匹配，KMP算法使用了一个小技巧，对模式串不同长度的子串寻找该子串对应的最长相同前后缀。例如，源字符串$s$和模式串$p$，当匹配到模式串$j$位置时，我们发现源字符串和模式串对应位置不相同，这时候简单的做法是重新从源字符串的上一次开始位置的下一个位置与模式串进行对比，但是如果我们能发现模式串到$j$位置之前的字符串存在$k$个前缀字符$p[:k]$与k个后缀字符$p[j-k:j]$相同，这时候我们可以直接从模式串的第$k+1$个进行匹配。具体见下图： 提前求出模式串的每个每个位置的最长相同前缀和后缀，在匹配失败的时候能够使得源字符串遍历的位置不变，快速确定模式串重新匹配的位置。该算法的关键在生成模式串的重新匹配位置数组。具体算法如下： 1234567891011121314151617181920//初始化next数组为[-1, 0, ....]char *p = \"\";int pLen = strlen(p);int *next = new int[pLen];next[0] = -1;next[1] = 0;int tmp;for(int i = 2; i &lt; pLen; i++)&#123; tmp = i; next[i] = 0; //当前位置的最长前后缀为之前的最长前缀+1,如果改签后缀后一个字符等于第当前位置字符，否则一直判断到不存在就重新匹配为0; while(tmp &gt; 0)&#123; if(p[next[i-1]] == p[i-1])&#123; next[i] = next[i-1] + 1; break; &#125;else&#123; tmp = next[i - 1]; &#125; &#125;&#125; 3. AC算法AC算法主要是解决线性时间内的多模式字符串匹配问题。","categories":[],"tags":[]},{"title":"数据挖掘之数据清洗","slug":"数据挖掘之数据清洗","date":"2019-12-14T16:21:39.000Z","updated":"2019-12-14T16:21:39.586Z","comments":true,"path":"2019/12/15/数据挖掘之数据清洗/","link":"","permalink":"http://dwkegu.github.io/2019/12/15/数据挖掘之数据清洗/","excerpt":"","text":"","categories":[],"tags":[]},{"title":"自然语言处理之分词篇","slug":"自然语言处理之分词篇","date":"2019-12-14T16:20:38.000Z","updated":"2020-02-07T13:21:27.437Z","comments":true,"path":"2019/12/15/自然语言处理之分词篇/","link":"","permalink":"http://dwkegu.github.io/2019/12/15/自然语言处理之分词篇/","excerpt":"","text":"自然语言处理中的分词作用自然语言处理过程中，经常拿到的原始数据都是非结构化的数据，比如英文中，拿到的字符串数据，并不是一个个单词对象，需要逐个将单词分隔开，得到单词的序列，英文中这个问题稍微简单点。因为大多数英文单词之间都有空格隔开，碰到的问题主要是很多英文单词词态有多种。相比而言，中文分词就复杂得多，中文字符串中的词没有明显的分隔符号，需要从语义层面进行分隔。 目前的分词算法分类大类分为三类，基于统计的方法，基于字典匹配的方法，基于深度学习的方法。 基于词典匹配的方法： 原理： 将待分割的字符串与字典中的单词进行匹配，达到匹配则将该位置作为切分点，匹配失败通过调整或者重新选择，迭代循环，知道完成。一般匹配的算法有正向最大匹配，逆向最大匹配和双向最大匹配。 优缺点：有点主要是速度快，成本低，但是存在适应性差，准确率不高的问题。 基于统计的方法: 原理：一般利用HMM，CRF，SVM等算法进行分隔，考虑到单词联合分布概率，也考虑到了上下文场景，在大多数场景下都表现不错，常见的有NLTK等工具采用该方法。 优缺点：适应性强，准确率相对较高，成本高，分隔速度较慢 基于深度学习的方法： 原理：将深度学习模型（如LSTM）结合CRF等模型实现序列标注分割。 优缺点：准确率很高，上下文依赖比较强。速度较慢 目前的英文分词工具主要有： Keras 目前未找到详细文档说明 Spacy 深度学习模型分词 NLTK 采用wordnet分词 allennlp 该工具集成了多种英文分词方式","categories":[],"tags":[]},{"title":"redis篇1","slug":"redis篇1","date":"2019-12-14T16:08:03.000Z","updated":"2019-12-16T16:45:00.003Z","comments":true,"path":"2019/12/15/redis篇1/","link":"","permalink":"http://dwkegu.github.io/2019/12/15/redis篇1/","excerpt":"","text":"redis基础介绍主要介绍redis原理基础和架构。 Redis是一款C语言开发的key-Struct pair的高性能内存数据库。Redis的特点主要是速度快，存在于内存中，也可以持久化，支持多种数据类型，支持多种语言的客户端，也支持发布订阅、Lua脚本、事务、Pipeline等功能。 这里我们罗列一下redis性能数据： 读写速度 千万次/秒 单线程网络请求（可以开启多线程） 持久化方式如下： RDB: 指定时间间隔内异步将内存数据生成文件数据写到磁盘 AOF: 将每次的操作数据都写到AOF文件，然后配置AOF文件写磁盘的规则。 Redis支持八种数据结构，分别是： String（字符串） Hash（哈希，key和value都是字符串） List（字符串列表） Set（字符串集合） Sorted Set （字符串有序集合，可以选择排序后一定范围的对象） Zset（即Sorted Set有序集合） Bits Array （二进制数组） Streams (流， 提供抽象日志数据类型的类似映射项的仅追加集合） Redis同时支持分布式，数据同步的方式是主从复制。用户可以通过执行SLAVEOF命令或者SLAVEOF选项，让从服务器去复制主服务器。Redis 2.6之后提供了哨兵机制，去监控Redis系统运行状态，哨兵可以启动多个，其功能主要是两个 监控所有的节点数据库是否正常运行 主数据库出现故障时，可以通过投票机制在从数据库中选出新的主数据库。 Redis 3.0引入了集群支持。 Redis 数据结构详细介绍Redis的Key 类型： Redis的Key是二进制安全的，也就是说可以用任意的二进制序列作为Key，甚至可以是空字符串。对于Key有少数注意事项： Key太长是不推荐的，原因是因为不仅占内存过大，而且在查找的时候进行key比较会比较耗时，当key比较长的时候，一个比较好的方案是对它进行hash（例如SHA1)。 太短的key也不推荐，有时候为了key过短，没有标明它的含义，虽然它占用跟少的内存，但可读性不佳，因此在设计的时候，我们需要在可读性和内存消耗上取得平衡。 key命名的时候尽量按照一定的模式 例如 data_type:id，甚至可以更多 data_type: id:target_type Redis String类型: redis最常见的数据类型，并且唯一存在于分布式系统中的数据类型。Redis中的value可以是任意类型的string（二进制类型）,也就是说你可以任意格式的数据转合成二进制的string然后存放到Redis里面，但是单个value文件大小不能超过512MB。虽然string类型是基础类型，但是仍然支持一些基础的操作，例如(在redis-cli中）： &gt;set counter 100OK&gt; incr counter(integer) 101&gt; incrby counter 50(integer) 151 incr命令会自动将string类型的value转换成integer类型，然后加1，然后加整形结果转换成字符串，更新原来的value。类似的命令还有INCBY， DECR， DECRBY。注意，这些命令的操作都是原子的，不存在脏读和幻度，重复写等问题。对于相同时搜索多个key或者设置多个key的情况，可以使用mset, mget命令。 常用命令： set (mset) get (mget) exist del type Redis周期：在redis中可以为每个key指定一个生存时间，在该周期内该key存在，超过该时间该key将会被自动删除。","categories":[],"tags":[]},{"title":"traffic prediction","slug":"traffic-prediction","date":"2019-09-10T17:08:11.000Z","updated":"2019-09-10T17:08:11.500Z","comments":true,"path":"2019/09/11/traffic-prediction/","link":"","permalink":"http://dwkegu.github.io/2019/09/11/traffic-prediction/","excerpt":"","text":"","categories":[],"tags":[]},{"title":"Hello World","slug":"hello-world","date":"2019-09-10T08:07:46.257Z","updated":"2019-09-10T08:07:46.257Z","comments":true,"path":"2019/09/10/hello-world/","link":"","permalink":"http://dwkegu.github.io/2019/09/10/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[],"tags":[]}]}